from src.experiment.prepare_data import process_data
from src.experiment.finetuner import finetune
from src.experiment.eval import evaluate_model

import os
import torch
import torch.distributed as dist
import torch.multiprocessing as mp
import argparse
import numpy as np

def get_args():
    parser = argparse.ArgumentParser(description="Full experiment pipeline. Data processing, finetuning, and evaluation.")
    subparsers = parser.add_subparsers(dest='pipe_type', required=True)

    # data parser
    data_parser = subparsers.add_parser('data', help='Data processing.')
    data_parser.add_argument('--metadata_path', '-m', type=str, help="Path to metadata tsv file.")
    data_parser.add_argument('--images_path', '-i', type=str, help="Path to images folder.")
    data_parser.add_argument('--splits_path', '-s', type=str, help="Folder path to save test/train/val splits in.")

    # finetune parser
    finetune_parser = subparsers.add_parser('finetune', help='Finetune Long-CLIP.')
    finetune_parser.add_argument('--splits_path', '-s', type=str, help="Folder to load the splits from.")
    finetune_parser.add_argument('--corrupted', '-x', type=str, help="Path to the .txt file that contains missing or corrupted images (the .txt is generated by data pipe).")
    finetune_parser.add_argument('--c_input_path', '-c', type=str, help="Path to Long-CLIP checkpoint that you wish to finetune.")
    finetune_parser.add_argument('--c_output_path', '-o', type=str, help="Folder path to save the checkpoints and logs generated by finetune pipe.")
    finetune_parser.add_argument('--distributed', '-d', action="store_true", help="Multi-gpu finetuning. This will use all available GPUs to improve finetuning.")
    finetune_parser.add_argument('--batch_size', '-b', type=int, default=30, help="Finetuning batch_size, defaults to 30.")

    # evaluate parser
    evaluate_parser = subparsers.add_parser('evaluate', help='Evaluate model performance.')
    evaluate_parser.add_argument('--c_input_path', '-c', type=str, help="Path to Long-CLIP checkpoint that you wish to evaluate.")
    evaluate_parser.add_argument('--corrupted', '-x', type=str, help="Path to the .txt file that contains missing or corrupted images (the .txt is generated by data pipe).")
    evaluate_parser.add_argument('--test_split_path', '-t', type=str, help="Path to test split .npy file (generated by data pipe).")
    evaluate_parser.add_argument('--return_mean', '-r', action='store_true', default=True, help="Defaults to True. If True, returns mean of each metric. If False, returns dict with metric for each query.")
    evaluate_parser.add_argument('--qrel_input_path', '-qi', type=str, help="(Optional) Qrel .json path to load in. If no path provided, then a new Qrel will be constructed.")
    evaluate_parser.add_argument('--qrel_output_path', '-qo', type=str, help="(Optional) .json path to save Qrel to.")
    evaluate_parser.add_argument('--eval_output_path', '-e', type=str, help="(Optional) .json path to save results in. If no path provided, results will simply be printed.")
    evaluate_parser.add_argument('--batch_size', '-b', type=int, default=100, help="Max number of samples per batch during encoding. Make this larger to speed up encoding, or smaller to prevent out of memory errors.")

    # complete parser (TBD)
    complete_parser = subparsers.add_parser('complete', help='Run complete experiment with pre-determined hyper-parameters.')

    return parser.parse_args()

def main():
    args = get_args()

    match args.pipe_type.lower():
        case 'data':
            if not (args.metadata_path and args.images_path and args.splits_path):
                raise argparse.ArgumentError(None, "Missing required arguments for data pipe. Usage: data -m <metadata_path> -i <images_path> -s <save_splits_path>.")
            train_split, val_split, test_split = process_data(args.metadata_path, args.images_path, validate_data=True)
            if not os.path.exists(args.splits_path):
                os.mkdir(args.splits_path)
            with open(os.path.join(args.splits_path, 'train_split.npy'), 'wb') as f1:
                np.save(f1, train_split)
            with open(os.path.join(args.splits_path, 'val_split.npy'), 'wb') as f2:
                np.save(f2, val_split)
            with open(os.path.join(args.splits_path, 'test_split.npy'), 'wb') as f3:
                np.save(f3, test_split)

        case 'finetune':
            if not (args.splits_path and args.corrupted and args.c_input_path and args.c_output_path):
                raise argparse.ArgumentError(None, f"Missing required arguments for finetune pipe. Usage: finetune -s <splits_path> -x <corrupted_files_path> -c <checkpoint_input_path> -o <checkpoint_output_path>")
            if os.path.exists(args.c_output_path):
                raise FileExistsError(f"Designated output folder '{args.c_output_path}' already exists. Please delete it or provide a different output folder name for c_output_path.")
            os.mkdir(args.c_output_path)
            if args.distributed:
                os.environ["MASTER_ADDR"] = "localhost"
                os.environ["MASTER_PORT"] = "12354"
                world_size = torch.cuda.device_count()
                assert world_size >= 2, f"Distributed requires at least 2 GPUs to run, but got {world_size}"
                try:
                    mp.spawn(finetune, args=(args.distributed, args.splits_path, args.corrupted, args.c_input_path, args.c_output_path, 25, args.batch_size, world_size), nprocs=world_size, join=True)
                except:
                    if dist.is_initialized():
                        dist.destroy_process_group()
                    raise
            else:
                finetune(0, args.distributed, args.splits_path, args.corrupted, args.c_input_path, args.c_output_path, batch_size=args.batch_size)
            
        case 'evaluate':
            metrics = ['precision@1', 'mrr'] # Can modify desired metrics here. Reference Ranx library to get list of valid metric names.
            if not (args.c_input_path and args.test_split_path and args.corrupted):
                raise argparse.ArgumentError(None, f"Missing required arguments for evaluate pipe. Usage: evaluate -c <Long-CLIP checkpoint path> -t <test_split_path> -x <corrupted_files_path>")
            evaluate_model(args.c_input_path, args.test_split_path, args.corrupted, metrics, args.qrel_input_path, args.eval_output_path, args.qrel_output_path, args.return_mean, args.batch_size)

        case 'complete':
            if not (args.metadata_path and args.images_path):
                raise argparse.ArgumentError(None, "Missing required arguments for complete pipe. Usage: complete -m <metadata_path> -i <images_path>")
            train_split, val_split, test_split = process_data(args.metadata_path, args.images_path, validate_data=True)

if __name__ == "__main__":
    main() # Wrapped code in main function so that spawned processes don't re-run everything.